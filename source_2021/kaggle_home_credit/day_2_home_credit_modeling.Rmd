---
title: "day_1_data_import"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction 

## 대회 개요
- 

## 데이터 파일 구조
- 데이터 파일 구조는 크게 2가지로 나뉠 수 있다. 

![](img/map.png)

- Credit Bureau 파일 구조와 Home Credit 파일 구조로 분리할 수 있음. 
- Bureau (External File)
- Home Credit (Internal File)
  + 현재 Home Credit File (Application train/test)
  + 이전 Home Credit File (Other's)
  
## 평가 지표
- 제출한 파일은 예측 확률과 기존 관측 대상 사이의 [ROC Curve](http://en.wikipedia.org/wiki/Receiver_operating_characteristic)로 평가 한다. 

# 분석 준비

## 패키지 불러오기
- 주요 패키지를 불러오도록 한다. 

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(skimr)
library(GGally)
library(plotly)
library(viridis)
library(caret)
library(DT)
library(data.table)
library(lightgbm)
library(xgboost)
library(kableExtra)
library(magrittr)
```

## 데이터 불러오기
- 이번에는 `fread()`를 활용하여 데이터를 불러도록 한다. 

### train
```{r}
na_strings = c("NA", "NaN", "?", "")

train = fread('data/home-credit-default-risk/application_train.csv', 
              stringsAsFactors = FALSE, 
              data.table = FALSE, na.strings = na_strings)

# train %>% skim()
dim(train)
```

### test 
```{r}
test = fread('data/home-credit-default-risk/application_test.csv', 
              stringsAsFactors = FALSE, 
              data.table = FALSE, na.strings = na_strings)

dim(test)
```

### bureau
```{r}
bureau = fread('data/home-credit-default-risk/bureau.csv', 
              stringsAsFactors = FALSE, 
              data.table = FALSE, na.strings = na_strings)

dim(bureau)
bureau %>% skim()
```

### previous application
```{r}
prev = fread('data/home-credit-default-risk/previous_application.csv', 
              stringsAsFactors = FALSE, 
              data.table = FALSE, na.strings = na_strings)

dim(prev)
prev %>% skim()
```


### bureau balance

```{r}
bur_balance = fread('data/home-credit-default-risk/bureau_balance.csv', 
              stringsAsFactors = FALSE, 
              data.table = FALSE, na.strings = na_strings)

dim(bur_balance)
bur_balance %>% skim()
```

### credit card balance

```{r}
credit_card_balance = fread('data/home-credit-default-risk/credit_card_balance.csv', 
              stringsAsFactors = FALSE, 
              data.table = FALSE, na.strings = na_strings)

dim(credit_card_balance)
credit_card_balance %>% skim()
```


### installments payments

```{r}
payments = fread('data/home-credit-default-risk/installments_payments.csv', 
              stringsAsFactors = FALSE, 
              data.table = FALSE, na.strings = na_strings)

dim(payments)
payments %>% skim()
```

### POS Cash Balance
```{r}
p_cash_balance = fread('data/home-credit-default-risk/POS_CASH_balance.csv', 
              stringsAsFactors = FALSE, 
              data.table = FALSE, na.strings = na_strings)

dim(p_cash_balance)
p_cash_balance %>% skim()
```




# 데이터 전처리

## 데이터 특징
- 모델링을 위한 데이터 전처리에서 가장 기본이 되는 train 데이터의 id를 확인해보면, 각 ID당 1개의 행(row)만 존재하는 것을 확인할 수 있다. 

```{r}
table(train$SK_ID_CURR) %>% head(10)
```
- 그런데, 다른 데이터셋의 경우, ID마다 서로 다른 행(row) 개수가 나타나는 것을 볼 수 있다. 
- 이 때에는 우선 ID마다 Group by를 통해서 행의 결과를 단일하게 맞출 필요가 있다. 

```{r}
table(bur_balance$SK_ID_BUREAU) %>% head(10)
```

## sum_bureau_balance


```{r}
cat("Processing...\n")
glimpse(bur_balance)

stat_fn = list(mean = mean, sd = sd)

sum_bur_balance = bur_balance %>% 
  mutate_if(is.character, funs(factor(.) %>% as.integer)) %>% # Ordinal Encoding
  group_by(SK_ID_BUREAU) %>% 
  mutate(SK_ID_BUREAU = as.character(SK_ID_BUREAU)) %>% 
  summarise_all(stat_fn, na.rm = TRUE) 

rm(bur_balance); gc()

sum_bureau = bureau %>% 
  mutate(SK_ID_BUREAU = as.character(SK_ID_BUREAU)) %>% 
  left_join(sum_bur_balance, by = "SK_ID_BUREAU") %>% 
  select(-SK_ID_BUREAU) %>% 
  mutate_if(is.character, funs(factor(.) %>% as.integer)) %>% 
  group_by(SK_ID_CURR) %>% 
  summarise_all(stat_fn)

rm(bureau, sum_bur_balance); gc()
```
# Data Merge

```{r}
train$SK_ID_CURR = as.character(train$SK_ID_CURR)
test$SK_ID_CURR = as.character(test$SK_ID_CURR)
sum_bureau$SK_ID_CURR = as.character(sum_bureau$SK_ID_CURR)

tri = 1:nrow(train)
y = train$TARGET
length(y); length(tri)
```


```{r}
train_test = train %>% 
  dplyr::select(-TARGET) %>% 
  bind_rows(test) %>% 
  left_join(sum_bureau, by = "SK_ID_CURR") %>% 
  select(-SK_ID_CURR) %>% 
  mutate_if(is.character, funs(factor(.) %>% as.integer)) %>% 
    mutate(na = apply(., 1, function(x) sum(is.na(x))),
         DAYS_EMPLOYED = ifelse(DAYS_EMPLOYED == 365243, NA, DAYS_EMPLOYED),
         DAYS_EMPLOYED_PERC = sqrt(DAYS_EMPLOYED / DAYS_BIRTH),
         INCOME_CREDIT_PERC = AMT_INCOME_TOTAL / AMT_CREDIT,
         INCOME_PER_PERSON = log1p(AMT_INCOME_TOTAL / CNT_FAM_MEMBERS),
         ANNUITY_INCOME_PERC = sqrt(AMT_ANNUITY / (1 + AMT_INCOME_TOTAL)),
         LOAN_INCOME_RATIO = AMT_CREDIT / AMT_INCOME_TOTAL,
         ANNUITY_LENGTH = AMT_CREDIT / AMT_ANNUITY,
         CHILDREN_RATIO = CNT_CHILDREN / CNT_FAM_MEMBERS, 
         CREDIT_TO_GOODS_RATIO = AMT_CREDIT / AMT_GOODS_PRICE,
         INC_PER_CHLD = AMT_INCOME_TOTAL / (1 + CNT_CHILDREN),
         SOURCES_PROD = EXT_SOURCE_1 * EXT_SOURCE_2 * EXT_SOURCE_3,
         CAR_TO_BIRTH_RATIO = OWN_CAR_AGE / DAYS_BIRTH,
         CAR_TO_EMPLOY_RATIO = OWN_CAR_AGE / DAYS_EMPLOYED,
         PHONE_TO_BIRTH_RATIO = DAYS_LAST_PHONE_CHANGE / DAYS_BIRTH,
         PHONE_TO_EMPLOY_RATIO = DAYS_LAST_PHONE_CHANGE / DAYS_EMPLOYED) 

train_test %>% glimpse()
```

## FLAG_DOC

```{r}
docs = str_subset(names(train), "FLAG_DOC")
live = str_subset(names(train), "(?!NFLAG_)(?!FLAG_DOC)(?!_FLAG_)FLAG_")

inc_by_org <- train_test %>% 
  group_by(ORGANIZATION_TYPE) %>% 
  summarise(m = median(AMT_INCOME_TOTAL)) %$% 
  setNames(as.list(m), ORGANIZATION_TYPE)

# install.packages("moments")
final_df <- train_test %>% 
  mutate(DOC_IND_KURT = apply(train_test[, docs], 1, moments::kurtosis),
         LIVE_IND_SUM = apply(train_test[, live], 1, sum),
         NEW_INC_BY_ORG = recode(train_test$ORGANIZATION_TYPE, !!!inc_by_org),
         NEW_EXT_SOURCES_MEAN = apply(train_test[, c("EXT_SOURCE_1", "EXT_SOURCE_2", "EXT_SOURCE_3")], 1, mean),
         NEW_SCORES_STD = apply(train_test[, c("EXT_SOURCE_1", "EXT_SOURCE_2", "EXT_SOURCE_3")], 1, sd))%>%
  mutate_all(funs(ifelse(is.nan(.), NA, .))) %>% 
  mutate_all(funs(ifelse(is.infinite(.), NA, .))) %>% 
  data.matrix()

length(final_df)
```

# Modeling

```{r}
cat("Preparing data...\n")
length(final_df)
dtest <- xgb.DMatrix(data = final_df[-tri, ])
```

```{r}
tr_te <- final_df[tri, ]
train_split <- caret::createDataPartition(y, p = 0.9, list = F) %>% c()

dtrain <- xgb.DMatrix(data = tr_te[train_split, ], label = y[train_split])
dval <- xgb.DMatrix(data = tr_te[-train_split, ], label = y[-train_split])
cols <- colnames(final_df)
```


```{r}
p <- list(objective = "binary:logistic",
          booster = "gbtree",
          eval_metric = "auc",
          nthread = 6, 
          eta = 0.05,
          max_depth = 6,
          min_child_weight = 30,
          gamma = 0,
          subsample = 0.85,
          colsample_bytree = 0.7,
          colsample_bylevel = 0.632,
          alpha = 0,
          lambda = 0,
          nrounds = 100) # 3000

set.seed(0)
m_xgb <- xgb.train(p, dtrain, p$nrounds, list(val = dval), print_every_n = 50, early_stopping_rounds = 300)

xgb.importance(cols, model=m_xgb) %>% 
  xgb.plot.importance(top_n = 30)
```
# Submission 

### Sample Submission
```{r}
read_csv("data/home-credit-default-risk/sample_submission.csv") %>%  
  mutate(SK_ID_CURR = as.integer(SK_ID_CURR),
         TARGET = predict(m_xgb, dtest)) %>%
  write_csv(paste0("data/home-credit-default-risk/my_xgb_", round(m_xgb$best_score, 5), ".csv"))
```

